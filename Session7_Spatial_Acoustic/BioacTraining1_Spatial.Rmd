---
title: "Bioacoustics Training - Spatial Display of Audio Data and Acoustic Indices"
author: "Carlos Abrahams"
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes:
    - \usepackage{lineno}
    - \linenumbers
output:
  pdf_document: default
  word_document: default
  html_document:
    fig_caption: yes
    number_sections: yes
geometry: margin=2cm
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```


# SPATIAL DISPLAY OF AUDIO DATA

Audio data can be linked to geographical information, either through embedding geographical data within you audio dataset during recording (i.e. automated georeferencing of individual sound files), or by combining seperate audio and geographical datasets during processing. We'll look at both using Google Earth, R and QGIS.

\newpage

## Displaying an EM Touch session.kml file in Google Earth

Access the provided data file "Session 20160606_214102.kml" (in EMT_Thurmaston zip).  Note the filename has been automatically generated using the recording start date and time. Open this file using Google Earth.

This data is from a bat transect recorded using an EM Touch. This bat detector uses the iPad's GPS chip to record both the transect route and the location of all bat detections. When downloaded from the tablet, the EM Touch provides a kml for the recording session, together with a bundle of corresponding .wav files (the latter has not been provided today).

Once opened you should see a path (line) for the transect route, and a placemark for the location of all bat detections. Each detection placemark has a name matching the corresponding wav file.

You can click on the detection placemarks to get the details on each and use the right-click 'Get Info' to check the length of the transect.


## Displaying an EM Touch .csv file in R

We'll use some R packages to display some more data for the same site. This data was downloaded from the EM Touch and the automatic identification were manually confirmed - so it has a 'MANUAL' column, as well as the automated species name. 

The packages we'll be using may need installing into R, as they are not part of the basic installation. If you don't have them installed already, then run the following lines, after removing the #.
\newline


```{r install packages}
#Install packages

#The commands below are commented out, using the hashtag, as we don't want these to run everytime

#install.packages("tidyverse")

#install.packages("ggmap")

```


Now we can clear memory, activate the packages using the 'library' command, and use the following code to load and view the .csv with the transect data.
\newline

```{r Start packages, echo=T, results='hide'}

#Clear memory
rm(list=ls())

#Activate the ggmap package for this session using the 'library' command
library(ggmap)

#Activate the tidyverse package
library(tidyverse)

```

```{R Load transect csv}

#Load the .csv data
#Find the file named gpsthurm16.csv you have been provided with
#gpsdata <- read_csv(file.choose())

#To make your script reproducible, it would be better to use the actual filepath instead, as below
gpsdata <- read_csv("~/Dropbox (Personal)/Carlos - Paul Shared Folder/PR Statistics Course/Datasets/EMtouch Thurmaston/gpsthurm16.csv")

#Take a look at your data to check its structure using glimpse
glimpse(gpsdata)

#You can also use summary to take a different sort of look
summary(gpsdata)

#Check what species have been manually confirmed using unique command
unique(gpsdata$MANUAL)

```


You'll note that there are 1638 wav files listed, but many of these are 'noise' and 'NoID' detections.  We don't want these, so will filter then out from the dataset.  This will reduce the number of rows in the .csv to 287.
\newline

```{r filter noise}

#Filter to remove noise and noID files
gpsdata <- filter(gpsdata, MANUAL != "NOISE" & MANUAL != "NoID")

#Check which species remain
unique(gpsdata$MANUAL)

```


The dataset has now been wrangled into shape, leaving only the species registrations we are after.  Let's map these using ggmap.  First we'll download a basemap from the internet (or upload from our computers, if we don't have access) - and plot this.
\newline

```{r get a basemap}

#Download a base map, using lat and long coordinates for the site 
#Zoom level goes from 3 to 20, 3 being continent level, 10 being city-scale, 20 being single building


basemap <- get_stamenmap(bbox = c(left = -1.08, bottom = 52.655, right = -1.058, top = 52.675), zoom = 14)

#Sometimes this can be slow to load, so you may want to save the ggmap object and then load the file instead
# save(basemap, file = "mybasemap.RData")
# load(file = "mybasemap.RData")

# Display the basemap
# This will appear in the Plots window if in a basic script, or below this chunk in Markdown 
ggmap(basemap)


```


Then we'll add all of the bat detection registrations, using a colour for each species.


```{r draw dot map}
#Draw dot plan for each detection
ggmap(basemap) +
  geom_point(aes(x= LONG, y= LATITUDE, colour = MANUAL), data = gpsdata)


```


Now that we have the points plotted, we'll develop this further, with a heatmap. This calculates and draws a density plot over the baseplan, to give a contour map indicating bat activity levels.
\newline

```{r heatmap}

#Plot a density heatmap with data points overlaid
ggmap(basemap) + 
  stat_density2d(data = gpsdata, 
                 aes(x = LONG, y = LATITUDE),  alpha = 0.1,
                 bins = 10, geom = "polygon")  +
  geom_point(data = gpsdata, aes(x = LONG, y = LATITUDE, colour = MANUAL), size = 0.3)


```


That's a useful figure, but a bit confusing with eight species shown - some of which have widely differing habitat preferences.  It would be good to see a heatmap like this for each species - using a 'facet' plot.  We'll also add a title.
\newline

```{r facet heatmap}

#Plot the same density heatmap as before
ggmap(basemap) + 
  stat_density2d(data = gpsdata, 
                 aes(x = LONG, y = LATITUDE), alpha = 0.1,  
                 bins = 5, geom = "polygon")  +
  geom_point(data = gpsdata, aes(x = LONG, y = LATITUDE), size = 0.5) +
#But this time we'll 'facet' by species (using the MANUAL column)
  facet_wrap(~ MANUAL, ncol = 4) +
#And add a title
  ggtitle("Bat species distribution")

```

\newpage

# Displaying data using QGIS
We're going to use the same data as above, but using QGIS.  
These instructions are based on QGIS 3.4 on Mac OSX, some details may be different if you are running another version.

## Get data ready
Relocate the .kml file we were using earlier (we could also use the .csv if we wanted...)

## Open the software
Open QGIS
Select Project>New.  This will provide a blank main screen

## Get a webserver basemap
Select Plugins>Manage and Install Plugins
Find QuickMapServices Plugin on the list (you can use the search bar), and Install Plugin. Then Close.
Select Web>QuickMapServices>OpenStreetMap>OpenStreetMap
Find the Zoom In icon at left of toolbar and click on the map to zoom in to somewhere you know.
Use the Hand icon to move the map image about on the screen as necessary

## Select project coordinate reference system
Select Project>Project Properties
Select the CRS tab and choose “OSGB 1936 / British National Grid (EPSG:27700)”
Click Apply and OK
The text in bottom right of the window should now say EPSG:27700.

## Load your data layers
Select Layer>Add layer>Add vector layer
At Source, browse to the “Session...kml” file and click Open, and then Add
The .kml file includes two vector layers.  We want to add both.  Press Select All and OK.
This will load your data, but it might be hidden below the OpenStreetMap layer.
Click and drag in the Layers Panel at left to reorder your layers if needed. You’ll see a transect route line and a series of dots.

## Convert the .kml to a .shp GIS file
While your points layer is still highlighted, click on Layer>Save As
Ensure that Format says 'ESRI Shapefile'
Choose a filename and browse to a save location.
Now do the same for the line layer.

## Investigate your data layers
Click on the .shp point layer in the Layers Panel to highlight it.
Select the Identify tool (a blue i circle) and select some points to check the data.
You should see in the Identify Results Panel the information stored on this point

## Label your point layer
Highlight the point layer in the Layers Panel and then select Layer>Properties.  
Select the Labels tab. Where it says No labels, select Show labels for this layer.
Now select Label with: Name
Now select Text and change the colour to white
Click Apply and OK.
Your point data should now have the detection filename next to each point

## Make better point labels 
Highlight the point layer in the Layers Panel and then select Layer>Properties.  
Select the Labels tab. Next to the Label with:Name field is an E expression button. Press this to launch an Expression Dialog window.
Type a simple string expression into the left window: left(Name, 4)
Select OK to close and then Apply>OK
Your labels should now have the four-letter species code next to each point

## Add new data to your point layer
Add some additional points to the points layer....
Select the points layer in the Layers Panel, then click on the Toggle Editing yellow pencil icon at top left.
The Add Feature points icon just to the right of the pencil icon should now be active. Click on this.
Cursor over your map and click to create a new point feature. A window will launch. Enter data in the relevant fields. Click OK.  
Now click the yellow pencil again to toggle editing off. And maybe click save..?


## Style your line layer
Highlight the transect line layer in the Layers Panel and then select Layer>Properties.  
Select the Symbology tab. Experiment with Symbol Layer Type and different line styles.You can click Apply to see the effects of your changes without closing the Properties window. 
Click OK to finish.


## Style your point layer
Highlight the point layer in the Layers Panel and then select Layer>Properties.  
Select the Symbology tab. Change the top field from Single Symbol to Categorized
Next to the Label with:Name field is an E expression button. Press this to launch an Expression Dialog window.
Type a simple string expression into the left window: left(Name, 4)
Now click on Classify. This will group the data by species, and apply a different colour to each.
Click Apply and OK.
Your points are now colour coded based on species.


## Create a heatmap layer
Right click on your points layer, and Duplicate Layer
Highlight the new point layer copy in the Layers Panel and then select Layer>Properties.  
Select the Symbology tab. Change the top field to Heatmap, and press Apply
This will create a black-white heatmap, but with the background completely white.
Click on the Colour Ramp to launch a new window.
Change Color 1 to White 0% Opacity, and Color 2 to Red 100% opacity. Click OK
Now click on Apply to view this change
Change Radius to ~20, and click Apply.
Click OK when you are happy with the Heatmap layer.




\newpage

# ACOUSTIC INDICES

## Introduction
The acoustic data recorded using bioacoustic methods can be analysed in great depth to identify species, or even individual animals - but this can be time-consuming, and requires significant identification expertise. However, a  range of indices have been developed for characterising acoustic field recordings in broader terms, summarising audio data to produce numerical scores that are ecologically meaningful, and that can be to assess biodiversity, including species richness, community diversity, and functional traits.  An acoustic index is a statistic that summarizes some aspect of the distribution of acoustic energy and information in a recording (Towsey et al., 2014) - providing an indication of its ecological 'quality' and a link to biodiversity metrics. Acoustic indices are increaingly being used to characterise and investigate ecological recordings, without the need to recognise individual species.  

We will look at one sort of index - the Acoustic Complexity Index (ACI) - which is designed to be related to the diversity of bird song, and hence bird species richness.

## Acoustic Complexity Index

The ACI was developed to quantify complex biotic sounds according to the variability of the intensities recorded, while filtering out background human-generated noise (anthrophony). The algorithm is based on the observation that many biotic sounds, including bird songs (for which it was principally developed), typically have frequent dynamic changes in their volume, while many types of human generated noise have constant amplitude - such as the drones or rumbles of traffic noise (Farina 2008; Pieretti 2011). The ACI provides a measure of how much the sound intensity varies over time, by calculating the differences in amplitude, for a range of frequency bins, between adjacent time periods in a recording. In this way, the ACI extracts the majority of biologically produced sound while reducing the non-biotic sounds and the effects of distance of sound from the microphone. 

When applying the ACI, it is necessary to note that strong intensity modulations can sometimes be generated by humans, or weather conditions. The ACI is resistant to continuous noise, such as aeroplane flights overhead or traffic noise, but sensitive to variable noise sources such as rain and irregular machine activity. These intermittent, irregular man-made sounds can cause a rapid variation of intensities, and a correspondingly high ACI score. Accordingly, the ACI should be used preferably in more semi-natural soundscapes, where any anthropogenic noise present in the soundscape is characterized by constant intensities, rather than in complex, noisy urban environments. In addition, although the ACI algorithm reduces the variability introduced by the singing organisms being different distances from the recording microphones, it is still moderately sensitive to the proximity of the sound source and close sounds will result in a higher ACI value than those at greater distance.


```{r add libraries}
#You will need to make sure that the tidyverse, tuneR, seewave and lubridate packages are installed.
#Run the following code if needed
#install.packages("tidyverse", "tuneR", "seewave", "lubridate")

#Activate tidyverse package for data nhandling
library(tidyverse)
#Activate tuneR readWave import function
library(tuneR)  
#Activate seewave for ACI function
library(seewave)
#Activate seewave for ACI function
library(lubridate)


```

We're going to use the "Carsington 3day 3ARU" dataset that you have been provided with.  This consists of 1 minute wav files, recorded every hour at dawn, for 3 days at 3 automated recorder locations - a plantation, broadleaved woodland, and reedbed.  

Before that though, we'll start by just loading and displaying a single .wav file at a time, using some wav data built into the seewave package.

```{r view and ACI the seewave data files}

#Load the seewave lapwing call data
data(peewit)

#Display a spectrogram for the lapwing call data
spectro(peewit)

#Load the seewave song data for neotropical sparrow
data(tico)

#Display a spectrogram for the sparrow song data
spectro(tico)

#Calculate the ACI for the lapwing call
ACI(peewit)

#Calculate the ACI for the sparrow song
ACI(tico)

```
The ACI scores are 270.7 for the Sparrow song, and 239.9 for the lapwing.  These don't mean that much, but are an indication that the sparrow song has more volume variation than the lapwing call.

Now try this for some of our data.

```{r view and ACI some individual wav files}


#Read in a single .wave file of your choice from the dataset
example_wav <- readWave("~/Dropbox (Personal)/Carlos - Paul Shared Folder/PR Statistics Course/Datasets/Carsington 3day 3ARU/8621Reedbed/UNIT8621_20180430_063600.wav")

#I've provided one here above, but you can use the following code to import your own choice
#example_wav <- readWave(file.choose())

#Display a spectrogram of the wav
#You can use the flim variable to constrain the spectrogram frequency scale
spectro(example_wav, flim = c(0,12))

#Calculate the ACI score for the wav
ACI(example_wav)

```

We can do this same analysis for a set of .wav files using the following code.  

Warning - With the provided dataset of 45 files, each being recorded at 48kHz sample rate in stereo, this process takes 3-4 minutes on a relatively fast laptop.

```{r import acoustic data}

#Create a new R object, containing a list of all the .wav files in the dataset 
#You will need to provide your own filepath in the command below, pointing to the dataset location
wav_list <- list.files("~/Dropbox (Personal)/Carlos - Paul Shared Folder/PR Statistics Course/Datasets/Carsington 3day 3ARU", recursive = TRUE, full.names = TRUE)

#Now we need to create a blank vector object to write the ACI scores into
#We create a numeric list of [zero] numbers, the same length as the number of wav files
aci_list <- vector("double", length(wav_list))

#Read wavs and calculate ACI scores
#The code below uses a 'for' loop to read the wav, calculate ACI and write the result into aci_list
for (i in seq_along(wav_list)) {
wav <- readWave(str_c(wav_list[i]))
aci_list[[i]] <- ACI(wav)
}

#Combine file names and ACI scores
wav_aci <- as_tibble(cbind(wav_list, aci_list))
#Ensure the aci_list scores are numeric, and not listed as a character string
wav_aci$aci_list <- as.numeric(wav_aci$aci_list)



```

We now have a dataframe with the (very long) filename for each .wav file and the corresponding ACI score.  You can check this using the glimpse function.

```{r glimpse wav_aci file}

#Glimpse wav_aci
glimpse(wav_aci)

```

To allow further analysis, we want to get the recorder reference, date and time for each .wav file. We'll do this using some string functions to manipulate the filename, and functions from the 'lubridate' package to help with dates and times.

```{r generate recorder, date and time columns}


#Create a new recorder column from the filename string
wav_aci$recorder <- str_sub(wav_aci$wav_list, -28, -21)

#Create a date_time columnn
wav_aci$date <- ymd(str_sub(wav_aci$wav_list, -19, -12))

#Create a time column
wav_aci$time <- str_sub(wav_aci$wav_list, -10, -5)

#Create an hour column
wav_aci$hour <- str_sub(wav_aci$time, 1, 2)


```

Check your wav_aci dataframe again after these changes.  Maybe use summary this time?

```{r summary wav_aci file}

#Get summary of wav_aci
summary(wav_aci)

```

And let's plot a histogram of the ACI scores to check the data distribution.


```{r histogram of ACI}

#Plot a histogram of the ACI scores
ggplot(data = wav_aci) +
  geom_histogram(aes(x= aci_list), bins = 20)

```

To compare the ACI values at each recorder location, we can produce a boxplot to show the median and interquartiles for each location. Unit 8621 is the reedbed, 8552 the broadleaved woodland and 8535 the plantation.

```{r display ACI boxplot per recorder}

#Plot a boxplot, showuing ACI for each recorder location
ggplot() +
  geom_boxplot(data = wav_aci, aes(x = recorder, y = aci_list)) +  
  theme_classic() +
  xlab("Recorder") +
  ylab("ACI") 

```

Let's see how the ACI varies over time, using another boxplot to start with.

```{r display ACI against time}

#Plot a boxplot, showing the ACI scores for each hour recorded
ggplot(wav_aci, aes(x= hour, y = aci_list)) +
  geom_boxplot() +
  labs(title = "ACI scores per hour, summarised across all days and recorders")

```

Following that, let's plot a line graph to show the mean ACI at each site over the 3-day period, and then a smoothed line, with 95% CI, for all the data over the 3-day survey.

```{r display ACI against date}

#Produce summary of the ACI data, with the mean ACI for each day at each site
daymeanACI <- wav_aci %>%
  group_by(recorder, date) %>%
  summarise(mean(aci_list))

#Plot a line graph, with recorder location facet, various theme (appearance) changes and titles.
ggplot() +
  geom_line(data = daymeanACI, aes(x = date, y = `mean(aci_list)` )) +
  facet_wrap(~recorder) +
  theme_bw() +
  theme(strip.background = element_rect(colour="white", fill="white")) +
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
  xlab("date") +
  ylab("ACI") +
  labs(title ="ACI variation at each sampling location over 3 day recording period")

```

```{r display ACI against date 2, message=FALSE, error= FALSE}

#Plot a smooth fitted line with 95% CI to the ACI data
ggplot(data = wav_aci, aes(x = date, y = aci_list)) +
  geom_smooth(method = "loess") +
  theme_classic() +
  theme(strip.background = element_rect(colour="white", fill="white")) +
  xlab("Date") +
  ylab("ACI") +
  labs(title ="ACI variation over 3 day recording period")


```







